{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Motivation\n",
    "- Anomaly detection\n",
    "    - **In data mining, anomaly detection (also outlier detection) is the identification of items, events or observations which do not conform to an expected pattern or other items in a dataset.**\n",
    "    - You're pretty much looking at similar observations and checking if the new observations is different than what the data has been showing.\n",
    "- Density Estimation\n",
    "    - You're checking the prob. of how these are different. If the prob. is less than some epilson, then you know that this rarely happens and it should signal an anomaly\n",
    "<img src=\"../images/Andrew-chpt9-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Gaussian Distribution\n",
    "<img src=\"../images/Andrew-chpt9-2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/Andrew-chpt9-3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Algorithm\n",
    " - When you think about, it's quite simple\n",
    "    - You look at the problem and find the normal distribution of each row or observation\n",
    "    - Then you mulitply each of the normal distribution of each column for one row\n",
    "    - You then have an epilson and compare with the prob. of the product of each normal dist. \n",
    "    \n",
    "<img src=\"../images/Andrew-chpt9-4.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/Andrew-chpt9-5.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<img src=\"../images/Andrew-chpt9-6.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/Andrew-chpt9-7.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Anomaly Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing and Evaluating an Anomaly Detection System\n",
    "- Using the aircraft example:\n",
    "    - We can divide the data into two parts to see that\n",
    "        - The flaw example happens very infrequent\n",
    "- Remember that we are checking for the flaw occurence, where it happen very infrequent\n",
    "    - Thus, the results might be skewed\n",
    "    - A good way to check for the results is\n",
    "        - True positive, false positive, false negative, true negative\n",
    "        - Precision/Recall\n",
    "        - F1-Score\n",
    "\n",
    "### Anomaly Detection vs. Supervised Learning\n",
    "<img src=\"../images/Andrew-chpt9-8.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "- Anomaly Detection\n",
    "    - It's hard for a model to figure out the model bc there's not enough info.\n",
    "    - It's also good when these positive examples can be done in many ways\n",
    "<img src=\"../images/Andrew-chpt9-9.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "        \n",
    "### Choosing What Features to Use\n",
    "- If you have the data, and its gaussian, leave at that.\n",
    "- Now, if you're data is not gaussian, you can do some transformation with hopes that the data will be gaussian\n",
    "- There are different ways to play aroun with the data \n",
    "- There is not only one way to change the data into gaussian\n",
    "<img src=\"../images/anomaly-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>      \n",
    "<img src=\"../images/anomaly-2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Gaussian Distribution (Optional)\n",
    "### Multivariate Gaussian Distribution\n",
    "- When we look at the gaussian for each point in the vector, we might begin to think that the probability of it happening isn't that low as we would think. \n",
    "- In the given example, the model isn't picking the actual regression or shape of the data, and instead, it's focusing on the number around the data point.\n",
    "<img src=\"../images/anomaly-3.png\" alt=\"Drawing\" style=\"width: 600px;\"/> \n",
    "<img src=\"../images/anomaly-4.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<img src=\"../images/anomaly-5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/anomaly-6.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/anomaly-7.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- The way that the prob. are handled is by cort of creating a topography map\n",
    "\n",
    "<img src=\"../images/anomaly-8.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/anomaly-9.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- ** As you will see in the next image, we are assuming that in the matrix for SIGMA, the only time the multivariate will be a gaussian distribution is if it the outsides (lower left and upper right) are 0 and we the topography reflects a circular spheres around the mean**\n",
    "<img src=\"../images/anomaly-10.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/anomaly-11.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Ratings\n",
    "\n",
    "### Problem Formulation\n",
    "<img src=\"../images/prediction-1.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "### Content Based Recommendations\n",
    "- As we will see, we are adding some new features that categorized the data in romance and action\n",
    "- This then created a 3-D Vector with the first index as the row, then the next is the ratio the movie is to their respective category\n",
    "- We would then use this vector and mult. it tp the theta of the delta matrix of each user\n",
    "\n",
    "<img src=\"../images/prediction-2.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"../images/prediction-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "<img src=\"../images/prediction-4.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"../images/prediction-5.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "### Collaborative Filtering\n",
    "- We're reversed seeing what would we rate these movies, given the dislike or taste of these people and their movies\n",
    "- We can use either info. to find the remaining info.\n",
    "- In the more general sense, collaborative filtering is the process of filtering for information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc.\n",
    "<img src=\"../images/CollaborativeFiltering-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "- ** YOU CAN GUESS THE THETA, AND YOU'LL EVENTUALLY GET IT, BUT THIS IS NOT QUITE EFFICIENT**\n",
    "\n",
    "\n",
    "### Collaborative Filtering Algorithm\n",
    "<img src=\"../images/CollaborativeFiltering-2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Rank Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization: Low Rank Matrix Factorization\n",
    "- When looking at these problems, like the picture below, the user is listed as the column, and the movie is listed as the row\n",
    "<img src=\"../images/MatrixFactorization-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/MatrixFactorization-2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<img src=\"../images/MatrixFactorization-3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "### Implementational Detail: Mean Normalization\n",
    "- We see that when there's no data for a movie, the model will predict 0 for all the movies bc the first term will be 0 since x is 0 (bc we don't know what the user preference in features), this also applies to the second portion of the model\n",
    "- The third portion encourages the rating of the movies (the value of theta), will be 0. \n",
    "<img src=\"../images/MatrixFactorization-4.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "**Mean Normalization**\n",
    "- We use the average of each column and make a vector (n by 1)\n",
    "- This will only apply to the data that have some infor. and are NOT unknown\n",
    "- We then either subract the average to each data into a new matrix\n",
    "<img src=\"../images/MatrixFactorization-5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "- The bottom image shows that will still use theta^Theta * X, which will give us zero but now we add the mean term. SO, we are basically scoring the theta's with the average\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
