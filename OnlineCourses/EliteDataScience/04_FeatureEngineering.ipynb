{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro. \n",
    "- This is often one of the most valuable tasks a data scientist can do to improve model performance, for 3 big reasons:\n",
    "    - You can isolate and highlight key information, which helps your algorithms \"focus\" on what’s important.\n",
    "    - You can bring in your own domain expertise.\n",
    "    - Most importantly, once you understand the \"vocabulary\" of feature engineering, you can bring in other people’s domain expertise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction features\n",
    "- The first of these heuristics is checking to see if you can create any interaction features that make sense. These are combinations of two or more features.\n",
    "- By the way, in some contexts, \"interaction terms\" must be products between two variables. In our context, interaction features can be products, sums, or differences between two features.\n",
    "- **EXAMPLE**\n",
    "    - Let's say we already had a feature called 'num_schools', i.e. the number of schools within 5 miles of a property.\n",
    "    - Let's say we also had the feature 'median_school', i.e. the median quality score of those schools.\n",
    "    - However, we might suspect that what's really important is having many school options, but only if they are good.\n",
    "    - We could simple create a new feature 'school_score' = 'num_schools' x 'median_school'b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse classes\n",
    "- Sparse classes (in categorical features) are those that have very few total observations. They can be problematic for certain machine learning algorithms, causing models to be overfit.\n",
    "    - There's no formal rule of how many each class needs.\n",
    "    - It also depends on the size of your dataset and the number of other features you have.\n",
    "    - As a rule of thumb, we recommend combining classes until each one has at least ~50 observations. As with any \"rule\" of thumb, use this as a guideline (not actually as a rule).\n",
    "- **EXAMPLE**\n",
    "    - We might want to group 'Wood Siding', 'Wood Shingle', and 'Wood' into a single class. In fact, let's just label all of them as 'Wood'.\n",
    "    - We'd group 'Concrete Block', 'Stucco', 'Masonry', 'Other', and 'Asbestos shingle' into just 'Other'.\n",
    "- After combining sparse classes, we have fewer unique classes, but each one has more observations.\n",
    "- Often, an eyeball test is enough to decide if you want to group certain classes together.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "- Most machine learning algorithms cannot directly handle categorical features. Specifically, they cannot handle text values.\n",
    "- We need to create dummy variables for our categorical features.\n",
    "- Dummy variables are a set of binary (0 or 1) variables that each represent a single class from a categorical feature.\n",
    "- The information you represent is exactly the same, but this numeric representation allows you to pass the technical requirements for algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unused\n",
    "- Remove unused or redundant features from the dataset.\n",
    "- Unused features are those that don’t make sense to pass into our machine learning algorithms. \n",
    "- **EXAMPLE**\n",
    "    - ID columns\n",
    "    - Features that wouldn't be available at the time of prediction\n",
    "    - Other text descriptions\n",
    "- Redundant features would typically be those that have been replaced by other features that you’ve added during feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
