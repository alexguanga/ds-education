{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "- If you evaluate your model on the same data you used to train it, your model could be very overfit and you wouldn’t even know! A model should be judged on its ability to predict new, unseen data.\n",
    "- Therefore, you should have separate training and test subsets of your dataset.\n",
    "- **Training sets** are used to fit and tune your models. \n",
    "- **Test sets** are put aside as \"unseen\" data to evaluate your models.\n",
    "    - You should always split your data before doing anything else.\n",
    "    - This is the best way to get reliable estimates of your models’ performance.\n",
    "    - After splitting your data, don’t touch your test set until you’re ready to choose your final model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "- When we talk of tuning models, we specifically mean tuning hyperparameters.\n",
    "- **They key distinction is that model parameters can be learned directly from the training data while hyperparameters cannot.**\n",
    "\n",
    "\n",
    "- **MODEL PARAMETERS**\n",
    "    - Model parameters are learned attributes that define individual models.\n",
    "    - e.g. regression coefficients\n",
    "    - e.g. decision tree split locations\n",
    "    - They can be learned directly from the training data\n",
    "- **HYPERPARAMTERS**\n",
    "    - Hyperparameters express \"higher-level\" structural settings for algorithms.\n",
    "    - e.g. strength of the penalty used in regularized regression\n",
    "    - e.g. the number of trees to include in a random forest\n",
    "    - They are decided before fitting the model because they can't be learned from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "- Cross-validation is a method for getting a reliable estimate of model performance using only your training data.\n",
    "- There are several ways to cross-validate. The most common one, 10-fold cross-validation, breaks your training data into 10 equal parts (a.k.a. folds), essentially creating 10 miniature train/test splits.\n",
    "- These are the steps for 10-fold cross-validation:\n",
    "    - Split your data into 10 equal parts, or \"folds\".\n",
    "    - Train your model on 9 folds (e.g. the first 9 folds).\n",
    "    - Evaluate it on the 1 remaining \"hold-out\" fold.\n",
    "    - Perform steps (2) and (3) 10 times, each time holding out a different fold.\n",
    "    - Average the performance across all 10 hold-out folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and tune models\n",
    "- Now that we've split our dataset into training and test sets, and we've learned about hyperparameters and cross-validation, we're ready fit and tune our models.\n",
    "- Basically, all we need to do is perform the entire cross-validation loop detailed above on each set of hyperparameter values we'd like to try.\n",
    "- At the end of this process, you will have a cross-validated score for each set of hyperparameter values... for each algorithm.\n",
    "- Insert Image1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- There are a variety of performance metrics you could choose from. We won't spend too much time on them here, but in general:\n",
    "    - For regression tasks, we recommend Mean Squared Error (MSE) or Mean Absolute Error (MAE). (Lower values are better)\n",
    "    - For classification tasks, we recommend Area Under ROC Curve (AUROC). (Higher values are better)\n",
    "\n",
    "**STEPS**\n",
    "- Finally, use these questions to help you pick the winning model:\n",
    "- Which model had the best performance on the test set? (performance)\n",
    "- Does it perform well across various performance metrics? (robustness)\n",
    "- Did it also have (one of) the best cross-validated scores from the training set? (consistency)\n",
    "- Does it solve the original business problem? (win condition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
