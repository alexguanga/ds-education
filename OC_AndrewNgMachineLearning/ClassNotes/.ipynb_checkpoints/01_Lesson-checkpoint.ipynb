{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- *What is Machine Learning?* Tom Mitchell provides a more modern definition: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\"\n",
    "- Regression: Continous variables, predicts real-valued output\n",
    "- Classification: Discrete variables\n",
    "- When you have thousands of items, treat these problems are regression. \n",
    "- Example:\n",
    "    - Regression - Given a picture of a person, we have to predict their age on the basis of the given picture\n",
    "    - Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Cost Function \n",
    "- ** Supervised Learning **\n",
    "    - Supervised learning problems are categorized into \"regression\" and \"classification\" problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output.\n",
    "    \n",
    "    \n",
    "- ** Unsupervised Learning**\n",
    "    - Clustering: Putting things in groups like maybe type of customers for a retail business or clustering the people in a social media platform\n",
    "    - Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.\n",
    "    - With unsupervised learning there is no feedback based on the prediction results.\n",
    "\n",
    "\n",
    "- When the target variable that we‚Äôre trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem. When y can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem.\n",
    "\n",
    "\n",
    "- ** Linear regression: Cost Function**\n",
    "     - Choosing parameters\n",
    "     - This function is otherwise called the \"Squared error function\", or \"Mean squared error\". The mean is halved (1/2) as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the 1/2 term\n",
    "     - It's intersting bc we use the linear regression, and calculate the square error function but divide it over 1/2m, m being the total number of observations. Then, we plot the results we get against the beta_1 (or slope), beta_1 being in the x-axis\n",
    "     - If we plot a range of values, we see that we get a convex parabola.\n",
    "     - Our objective is to get the best possible line. The best possible line will be such so that the average squared vertical distances of the scattered points from the line will be the least. Ideally, the line should pass through all the points of our training data set. In such a case, the value of J(Œ∏0,Œ∏1) will be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Learning\n",
    "- ** Gradient Descent**\n",
    "    - So we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in hypothesis function. That's where gradient descent comes in.\n",
    "    - We put Œ∏0 on the x axis and Œ∏1 on the y axis, with the cost function on the vertical z axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters.\n",
    "    - We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the minimum.\n",
    "    - Reason being that when we calculate the Cost Function, we want the least cost, as in the error between the predicted minus the observed is quite small (the sum)\n",
    "    - You start at some point and from there, you keep moving in the direction where you find the minimal result and continue to do\n",
    "    - The way we do this is by taking the derivative (the tangential line to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent, and the size of each step is determined by the parameter Œ±, which is called the learning rate.\n",
    "    - alpha: the learning rate (large means we are taking large steps and small means we are taking small steps). This number is multiplied with the partial derivatives and can check the direction it should go.\n",
    "    - Uses partial derivatives\n",
    "    - There are setbacks if the alpha is too small, take a long time, or it's to large, takes big steps and you might miss your mark and could diverge\n",
    "    - This method looks at every example in the entire training set on every step, and is called batch gradient descent\n",
    "    - while gradient descent can be susceptible to local minima in general, the optimization problem we have posed here for linear regression has only one global, and no other local, optima; thus gradient descent always converges\n",
    "    \n",
    "    \n",
    "- **‚ÄúBatch‚Äù Gradient Descent**: Each step of gradient descent uses all the training examples.\n",
    "   \n",
    "   \n",
    "**Gradient Descent Tips**\n",
    "- Debugging gradient descent. Make a plot with number of iterations on the x-axis. Now plot the cost function, J(Œ∏) over the number of iterations of gradient descent. If J(Œ∏) ever increases, then you probably need to decrease Œ±.\n",
    "- Automatic convergence test. Declare convergence if J(Œ∏) decreases by less than E in one iteration, where E is some small value such as 10‚àí3. However in practice it's difficult to choose this threshold value.\n",
    "- It has been proven that if learning rate Œ± is sufficiently small, then J(Œ∏) will decrease on every iteration. Andrew Ng recommends decreasing Œ± by multiples of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Review\n",
    "- ** Matrixes **\n",
    "     - Rows x Columns\n",
    "     - Addition and Subraction\n",
    "         - Add by the specific place in the matrix to another matrix, the dimension will remain exactly the same\n",
    "     - Scalar Mult\n",
    "         - Mult. by a real number, multply each value in the matrix by the scalar value\n",
    "     - Combination of Operation\n",
    "         - The same order as regular algerbric math\n",
    "     - Matrix Vector Mult\n",
    "         - Remember, it's going down in the row * going to the right in the other col and then add all the products\n",
    "         - Can also use it for equation where the equation parameters are just a vector of numbers   \n",
    "     - Matrix Matrix Mult\n",
    "         - Can only multply the ones that match (first matrix's col and second matrix's row)\n",
    "         - Like with the matrix vector mult, you can use system of equation but now you can use more than one equation\n",
    "     - Properties\n",
    "         - IS Not cumlative, A x B is NOT B x A\n",
    "         - IS associative, if you A x B x C, can done as (A x B) x C or A x (B x C)\n",
    "         - 1 is the *Identity Matrix* , there are 1 in the diagnols. For any matrix A, A x I is I x A\n",
    "         - Inverse: A x A^-1 (inverse) = I\n",
    "         - Matrixes that don't have an inverse are called *singular or degenerate*\n",
    "         - Matrix Transpose: The first row of a matrix is the first column of the transpose matrix\n",
    "- ** Vector**: Only has one columns with n rows\n",
    "     - 1 indexed vs 0 indexed (The number of the index the rows begin with)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation and terms:\n",
    "\n",
    "- Aij refers to the element in the ith row and jth column of matrix A.\n",
    "- A vector with 'n' rows is referred to as an 'n'-dimensional vector\n",
    "- vi refers to the element in the ith row of the vector.\n",
    "- In general, all our vectors and matrices will be 1-indexed. Note that for some programming languages, the arrays are 0-indexed.\n",
    "- Matrices are usually denoted by uppercase names while vectors are lowercase.\n",
    "- \"Scalar\" means that an object is a single value, not a vector or matrix.\n",
    "- ‚Ñù refers to the set of scalar real numbers\n",
    "- ‚Ñùùïü refers to the set of n-dimensional vectors of real numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../images/image1.png\" alt=\"Drawing\" style=\"width: 800px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Notation**\n",
    "\n",
    "The Gradient Descent rule can be expressed as:\n",
    "\n",
    "Œ∏:=Œ∏‚àíŒ±‚àáJ(Œ∏)\n",
    "Where ‚àáJ(Œ∏) is a column vector of the form:\n",
    "<img src=\"../images/image2.png\" alt=\"Drawing\" style=\"width: 800px;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
