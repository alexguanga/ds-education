{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Reminder\n",
    "- Triangle is the uppercase delta, while the squiggly symbol is the lower case delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Not DESCRIBED in Andrew Ng's Course**\n",
    "- http://datathings.com/blog/post/neuralnet/ (Some intuition behind forward and back propogation\n",
    "- We have a set of inputs and output(s)\n",
    "- We create some function, of whatever we think it is, and check the results of our function with the inputs and compare it the actual output(s)\n",
    "- We then use a cost function to check the results, and get some information on how well/bad our parameters in our function did\n",
    "- For example, if we are using a linear problem, we would change the parameters(or theta) for a better model to minimize the cost function \n",
    "\n",
    "- ** Forward-propagate: directly applying the function. Back-propagate: knowing the derivative of the function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Forwardpropagation**\n",
    "- <img src=\"../images/Image6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function and Backpropagation\n",
    "- L =  = total number of layers in the network\n",
    "- sl = number of units (not counting bias unit) in layer l \n",
    "- K = number of output units/classes\n",
    "- \"Backpropagation\" is neural-network terminology for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression. Our goal is to compute: $minΘ_{J}$\n",
    "- Gradient Descent is a great way to compute each layer. Using the parameters for each layer, we use the result from the previous layer multiplied by the theta.\n",
    "\n",
    "\n",
    "- Using y(t), compute δ(L)=a(L)−y(t)\n",
    "    - Where L is our total number of layers and a(L) is the vector of outputs of the activation units for the last layer. So our \"error values\" for the last layer are simply the differences of our actual results in the last layer and the correct outputs in y. To get the delta values of the layers before the last layer, we can use an equation that steps us back from right to left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropogation in Practice \n",
    "- Learning Algorithm\n",
    "    - Have initial parameters $Θ_{1}$, $Θ_{2}$, $Θ_{3}$\n",
    "    - Unroll to get initialTheta\n",
    "- **Gradient Checking**\n",
    "    - ** Epsilon **: In mathematics, a small positive infinitesimal quantity, usually denoted epsilon or epsilon, whose limit is usually taken as epsilon->0.\n",
    "    - Implement backprop to calculate for DVec\n",
    "    - Implement numerical gradient check to compute gradApprox\n",
    "    - Make sure they have similar values\n",
    "    - Turn OFF Gradient Checking. Using backprop code for learning OR else your code will be running very slowly.\n",
    "- **Random Initialization**\n",
    "    - You can't initialize the parameters to 0 bc mathematically, you won't get the desired partial derivative \n",
    "    - Thus, you have to use the random feature\n",
    "    - Initializing all theta weights to zero does not work with neural networks. When we backpropagate, all nodes will update to the same value repeatedly. Instead we can randomly initialize our weights for our Θ matrices using the following method: <img src=\"../images/Image4.png\">\n",
    "    - rand(x,y) is just a function in octave that will initialize a matrix of random real numbers between 0 and 1.\n",
    "- ** Putting in Together **\n",
    "    1. Training a neural network\n",
    "        - Pick a network architecture - Meaning you must have to choose how much input, hidden, and output features you want in your algorithm\n",
    "        - Num. of input units is the dimension of features\n",
    "        - Num. of output units is the number of classes\n",
    "        - Reasonable default: 1 Hidden layer, or if >1 hidden layers, have some num. of hidden units in each layer\n",
    "    2. Randomly initilize weights\n",
    "    3. Implement forward propogagation\n",
    "    4. Implement code to compute cost function\n",
    "    5. Implement back prop. to compute the partial derivative\n",
    "    6. Use Gradient Checking\n",
    "    7. Use Gradient Descent or advanced optimization with backprop. to try to minimize as a function of parameters\n",
    "- Ideally, you want $hΘ(x(_i))$ ≈ y(i). This will minimize our cost function. However, keep in mind that J(Θ) is not convex and thus we can end up in a local minimum instead.\n",
    "<img src=\"../images/Image5.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
